import pandas as pd
import feedparser
import json
import time
import hashlib
import google.generativeai as genai
from datetime import datetime
from dateutil import parser as date_parser
from bs4 import BeautifulSoup
import os

# ==============================================================================
# [ì„¤ì •] ì‚¬ìš©ì í™˜ê²½ ì„¤ì •
# ==============================================================================
# 1. Gemini API í‚¤ (ë³¸ì¸ì˜ í‚¤ ì…ë ¥)
GEMINI_API_KEY = ""

# 2. íŒŒì¼ ê²½ë¡œ ì„¤ì •
INPUT_EXCEL_FILE = "C:/Users/Choi/Desktop/ì¼ë³¸ rss.xlsx"           # ì…ë ¥ ì—‘ì…€ íŒŒì¼
FILE_ORIGINAL_JSON = "C:/Users/Choi/Desktop/1_original_news.json"    # [ê²°ê³¼1] ì›ë³¸ ë°ì´í„° ì €ì¥ íŒŒì¼
FILE_TRANSLATED_JSON = "C:/Users/Choi/Desktop/2_translated_results.json" # [ê²°ê³¼2] ë²ˆì—­ëœ ê²°ê³¼ ë°ì´í„° ì €ì¥ íŒŒì¼

# 3. Gemini ëª¨ë¸ ì„¤ì •
genai.configure(api_key=GEMINI_API_KEY)
model = genai.GenerativeModel('gemini-2.0-flash')

# ==============================================================================
# [Helper Functions] ë°ì´í„° ê°€ê³µìš© í•¨ìˆ˜ë“¤
# ==============================================================================

def clean_html(raw_html):
    """HTML íƒœê·¸ ì œê±°"""
    if not raw_html: return ""
    soup = BeautifulSoup(raw_html, "html.parser")
    return soup.get_text(strip=True)

def generate_local_id(title):
    """ì„œë²„ ì—†ì´ë„ ê´€ë¦¬í•  ìˆ˜ ìˆë„ë¡ ì œëª© ê¸°ë°˜ì˜ ê³ ìœ  ID ìƒì„± (MD5)"""
    return hashlib.md5(title.encode('utf-8')).hexdigest()

def normalize_date(date_str):
    """ë‚ ì§œ í˜•ì‹ì„ ISO 8601 í¬ë§·ìœ¼ë¡œ í†µì¼"""
    if not date_str:
        return datetime.now().astimezone().isoformat()
    try:
        dt = date_parser.parse(date_str)
        if dt.tzinfo is None:
            dt = dt.astimezone() 
        return dt.isoformat()
    except:
        return datetime.now().astimezone().isoformat()

def get_safe_category(text):
    """ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜ ë¡œì§"""
    text = text.lower()
    if 'economy' in text or 'business' in text or 'money' in text:
        return 'business'
    if 'tech' in text or 'science' in text:
        return 'tech'
    return 'world' # ê¸°ë³¸ê°’

def get_ai_translation(title, content):
    """Geminiì—ê²Œ ë²ˆì—­ ë° ìš”ì•½ ìš”ì²­"""
    prompt = f"""
    [ì—­í• ] ì „ë¬¸ ë²ˆì—­ê°€
    [ìš”ì²­]
    1. ì œëª©: í•œêµ­ì–´ë¡œ ë²ˆì—­ (translatedTitle)
    2. ë³¸ë¬¸: ì „ì²´ ë‚´ìš©ì„ ë¹ ì§ì—†ì´ í•œêµ­ì–´ë¡œ ë²ˆì—­ (translatedContent)
    3. ìš”ì•½: í•µì‹¬ ë‚´ìš©ì„ í•œêµ­ì–´ 3ì¤„ ì´ë‚´ë¡œ ìš”ì•½ (summaryText)
    
    [ì›ë¬¸]
    ì œëª©: {title}
    ë‚´ìš©: {content}
    
    [ì¶œë ¥ í¬ë§·] JSON Only (No Markdown)
    {{ "translatedTitle": "...", "translatedContent": "...", "summaryText": "..." }}
    """
    try:
        response = model.generate_content(prompt)
        text = response.text.replace("```json", "").replace("```", "").strip()
        return json.loads(text)
    except:
        return None

# ==============================================================================
# [Phase 1] RSS ìˆ˜ì§‘ -> ê°€ê³µ -> JSON ì €ì¥ (ì„œë²„ ì „ì†¡ X)
# ==============================================================================
def phase1_collect_news():
    print("\nğŸ“° [Phase 1] RSS ë‰´ìŠ¤ ìˆ˜ì§‘ ë° ì›ë³¸ ì €ì¥ ì‹œì‘...")
    
    if not os.path.exists(INPUT_EXCEL_FILE):
        print(f"âŒ ì—‘ì…€ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {INPUT_EXCEL_FILE}")
        return []
    
    df = pd.read_excel(INPUT_EXCEL_FILE)
    collected_articles = []
    
    for _, row in df.iterrows():
        press_name = row['ì–¸ë¡ ì‚¬']
        rss_url = row['RSSì£¼ì†Œ']
        print(f"   ã„´ ìˆ˜ì§‘ ì¤‘: {press_name}...")
        
        try:
            feed = feedparser.parse(rss_url)
            # í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ ì–¸ë¡ ì‚¬ë‹¹ 3ê°œì”©ë§Œ ìˆ˜ì§‘
            for entry in feed.entries[:3]:
                title = entry.title
                link = entry.link
                
                # ë³¸ë¬¸ ì¶”ì¶œ
                if hasattr(entry, 'content'):
                    raw_content = entry.content[0].value
                elif hasattr(entry, 'summary'):
                    raw_content = entry.summary
                else:
                    raw_content = title
                
                content = clean_html(raw_content)[:1000] # ê¸¸ì´ ì œí•œ
                
                # ë¡œì»¬ ID ìƒì„± (ì„œë²„ê°€ ì—†ìœ¼ë¯€ë¡œ ì§ì ‘ ìƒì„±)
                local_id = generate_local_id(title)

                # ë°ì´í„° ê°ì²´ ìƒì„± (ì„œë²„ í¬ë§·ê³¼ ìœ ì‚¬í•˜ê²Œ ìœ ì§€)
                article_obj = {
                    "articleId": local_id, # ë‚˜ì¤‘ì— ë§¤ì¹­í•  ID
                    "sourceType": "RSS",
                    "sourceName": press_name,
                    "categoryCode": get_safe_category(title + content),
                    "url": link,
                    "title": title,
                    "content": content,
                    "publishedAt": normalize_date(entry.get('published', '')),
                }
                collected_articles.append(article_obj)
        except Exception as e:
            print(f"      âš ï¸ ì—ëŸ¬: {e}")

    # ì›ë³¸ íŒŒì¼ ì €ì¥
    payload = {"articles": collected_articles}
    with open(FILE_ORIGINAL_JSON, 'w', encoding='utf-8') as f:
        json.dump(payload, f, ensure_ascii=False, indent=2)
    print(f"âœ… [ì €ì¥ 1] ì›ë³¸ íŒŒì¼ ìƒì„± ì™„ë£Œ ({len(collected_articles)}ê°œ): {FILE_ORIGINAL_JSON}")
    
    return collected_articles

# ==============================================================================
# [Phase 2] ìˆ˜ì§‘ëœ ë°ì´í„° ì½ê¸° -> AI ë²ˆì—­ -> JSON ì €ì¥ (ì„œë²„ ì „ì†¡ X)
# ==============================================================================
def phase2_translate_news(articles):
    if not articles:
        print("ğŸ“­ ë²ˆì—­í•  ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    print("\nğŸ¤– [Phase 2] AI ë²ˆì—­ ë° ê²°ê³¼ ì €ì¥ ì‹œì‘...")
    
    translated_results = []

    for idx, item in enumerate(articles):
        article_id = item.get("articleId")
        print(f"   â–¶ [{idx+1}/{len(articles)}] ë²ˆì—­ ì¤‘... (ID: {article_id[:8]}...)")
        
        ai_data = get_ai_translation(item.get("title"), item.get("content"))
        
        if ai_data:
            # ê²°ê³¼ ë°ì´í„° êµ¬ì„± (ìš”ì²­í•˜ì‹  í¬ë§· ì¤€ìˆ˜)
            result_payload = {
                "articleId": article_id,
                "languageTarget": "ko",
                "translatedTitle": ai_data.get("translatedTitle"),
                "translatedContent": ai_data.get("translatedContent"),
                "summaryText": ai_data.get("summaryText"),
                "modelName": "gemini-2.0-flash",
                # ì›ë³¸ ì •ë³´ë„ ê°™ì´ ë³´ê³  ì‹¶ë‹¤ë©´ ì•„ë˜ ì£¼ì„ í•´ì œ
                # "originalUrl": item.get("url"),
                # "publishedAt": item.get("publishedAt")
            }
            
            translated_results.append(result_payload)
            print("      âœ… ë²ˆì—­ ì„±ê³µ")
        else:
            print("      âŒ AI ì‘ë‹µ ì‹¤íŒ¨")
        
        time.sleep(1) # API ê³¼ë¶€í•˜ ë°©ì§€

    # ë²ˆì—­ëœ íŒŒì¼ ì €ì¥
    with open(FILE_TRANSLATED_JSON, 'w', encoding='utf-8') as f:
        json.dump(translated_results, f, ensure_ascii=False, indent=2)
    print(f"\nâœ… [ì €ì¥ 2] ë²ˆì—­ëœ íŒŒì¼ ìƒì„± ì™„ë£Œ: {FILE_TRANSLATED_JSON}")
    print("ğŸ‰ ëª¨ë“  ë¡œì»¬ ì‘ì—…ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")

# ==============================================================================
# ë©”ì¸ ì‹¤í–‰ë¶€
# ==============================================================================
if __name__ == "__main__":
    # 1. ìˆ˜ì§‘í•˜ê³  ì›ë³¸ ì €ì¥ (ì„œë²„ ì „ì†¡ ì•ˆ í•¨)
    collected_data = phase1_collect_news()
    
    # 2. ë°”ë¡œ ë²ˆì—­í•˜ê³  ê²°ê³¼ ì €ì¥ (ì„œë²„ ì „ì†¡ ì•ˆ í•¨)
    # Phase 1ì—ì„œ ìˆ˜ì§‘í•œ ë°ì´í„°ë¥¼ ë°”ë¡œ Phase 2ë¡œ ë„˜ê²¨ì¤ë‹ˆë‹¤.
    phase2_translate_news(collected_data)